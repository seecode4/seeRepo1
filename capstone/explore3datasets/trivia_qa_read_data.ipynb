{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG4flt1HKy7diMHg8V7hNg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seecode4/seeRepo1/blob/main/capstone/explore3datasets/trivia_qa_read_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TriviaQA\n",
        "\n",
        "A reading comprehension dataset containing over 650K question-answer-evidence triples is in TriviaQA.\n",
        "\n",
        "This was used in ACL 17 paper \"TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.\"\n",
        "The paper presents two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%).\n",
        "\n",
        "The capstone project can use this dataset to model and train to try and improve the performance from what is presented in this paper. Further, we can explore to see how well the models generalize. This could be studied using the game show Jeopardy dataset."
      ],
      "metadata": {
        "id": "Dq4vfcCtAlsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset tar.gz file and decompress it\n",
        "url = \"https://nlp.cs.washington.edu/triviaqa/data/triviaqa-unfiltered.tar.gz\"\n",
        "!pwd\n",
        "!ls\n",
        "!curl {url} | tar xz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouuavmkCBC_W",
        "outputId": "e0103ae6-528b-48aa-9c29-4e9c57561352"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  603M  100  603M    0     0  12.5M      0  0:00:48  0:00:48 --:--:-- 12.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check directory content\n",
        "!du -h /content/triviaqa-unfiltered\n",
        "!df\n",
        "!ls -l /content/triviaqa-unfiltered/\n",
        "# !cat /content/triviaqa-unfiltered/README"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmfoY4k9O-DE",
        "outputId": "b310d20b-4bbe-4624-9abb-8c3a8df06ee0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9G\t/content/triviaqa-unfiltered\n",
            "Filesystem     1K-blocks     Used Available Use% Mounted on\n",
            "overlay        112947452 35227340  77703728  32% /\n",
            "tmpfs              65536        0     65536   0% /dev\n",
            "shm              5989376        0   5989376   0% /dev/shm\n",
            "/dev/root        2019696  1180612    839084  59% /usr/sbin/docker-init\n",
            "tmpfs            6645228      112   6645116   1% /var/colab\n",
            "/dev/sda1       73032084 55416760  17598940  76% /kaggle/input\n",
            "tmpfs            6645228        0   6645228   0% /proc/acpi\n",
            "tmpfs            6645228        0   6645228   0% /proc/scsi\n",
            "tmpfs            6645228        0   6645228   0% /sys/firmware\n",
            "total 2938248\n",
            "-rw-rw-r-- 1 1000 1000       3260 May  4  2017 README\n",
            "-rw-rw-r-- 1 1000 1000  311475524 Jul 18  2017 unfiltered-web-dev.json\n",
            "-rw-rw-r-- 1 1000 1000  283196950 Jul 18  2017 unfiltered-web-test-without-answers.json\n",
            "-rw-rw-r-- 1 1000 1000 2414078634 Jul 18  2017 unfiltered-web-train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since these are large datasets, explore using ijson, used to read big json files"
      ],
      "metadata": {
        "id": "p8t_ulpEB9Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://www.kaggle.com/code/xxxxyyyy80008/how-to-read-a-big-json-file-with-python/notebook\n",
        "# Number of lines in test dataset\n",
        "%%time\n",
        "test_file = \"/content/triviaqa-unfiltered/unfiltered-web-test-without-answers.json\"\n",
        "num_lines_test = sum(1 for line in open(test_file))\n",
        "print(f'Num. of samples in test dataset: {num_lines_test:,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql1QIql7RcPi",
        "outputId": "81f6c920-e0a0-4de2-ab24-58f84bf9a317"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. of samples in test dataset: 3,837,331\n",
            "CPU times: user 2.13 s, sys: 72.9 ms, total: 2.2 s\n",
            "Wall time: 2.27 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of lines in train dataset\n",
        "%%time\n",
        "train_file = \"/content/triviaqa-unfiltered/unfiltered-web-train.json\"\n",
        "num_lines_train = sum(1 for line in open(train_file))\n",
        "print(f'Num. of samples in train dataset: {num_lines_train:,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84tjNRcASGGZ",
        "outputId": "3c92442f-614b-4681-b2c2-67a0cafbe5fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. of samples in train dataset: 34,184,870\n",
            "CPU times: user 15.3 s, sys: 880 ms, total: 16.2 s\n",
            "Wall time: 16.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just trying to read chunks did not help\n",
        "# Parse data by looking for <prefix, event, value>\n",
        "%%time\n",
        "import pandas as pd\n",
        "!pip install ijson\n",
        "from typing import KeysView\n",
        "import ijson\n",
        "# chunksize = 100000\n",
        "# chunks = pd.read_json(train_file, lines=True, chunksize=chunksize)\n",
        "# print(type(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMhyQSPES28n",
        "outputId": "65c090af-af76-4ff1-d540-962353a89a21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ijson\n",
            "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.3.0\n",
            "CPU times: user 588 ms, sys: 67.9 ms, total: 656 ms\n",
            "Wall time: 7.19 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefixes describe location of the keys or names in the object tree.\n",
        "Events report value types,\n",
        "*   mark the start (start_array)\n",
        "*   end of arrays (end_array)\n",
        "*   objects (start_map, end_map)\n",
        "*   mark keys (map_key)"
      ],
      "metadata": {
        "id": "A-xnZxFSF5hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate the data\n",
        "# Ref: https://www.aylakhan.tech/?p=27\n",
        "cnt = 0\n",
        "with open(train_file, 'r', encoding='utf-8') as fp:\n",
        "    parser = ijson.parse(fp)\n",
        "    for prefix, event, value in parser:\n",
        "      if (event=='start_map') or (event=='end_map') or (cnt % 10 == 0) or cnt < 10:\n",
        "        print('prefix={}, event={}, value={}, cnt={}'.format(prefix, event, value, cnt))\n",
        "      cnt += 1\n",
        "      if cnt > 70 or event=='end_map':\n",
        "        break\n",
        "print('--------')\n",
        "cnt = 0\n",
        "with open(test_file, 'r', encoding='utf-8') as fp:\n",
        "    parser = ijson.parse(fp)\n",
        "    for prefix, event, value in parser:\n",
        "      # print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
        "      cnt += 1\n",
        "      if cnt > 50 or event=='end_map':\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcZKbUS-TCGg",
        "outputId": "32a9b374-0928-465b-eba4-18c24f8f87a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prefix=, event=start_map, value=None, cnt=0\n",
            "prefix=, event=map_key, value=Data, cnt=1\n",
            "prefix=Data, event=start_array, value=None, cnt=2\n",
            "prefix=Data.item, event=start_map, value=None, cnt=3\n",
            "prefix=Data.item, event=map_key, value=Answer, cnt=4\n",
            "prefix=Data.item.Answer, event=start_map, value=None, cnt=5\n",
            "prefix=Data.item.Answer, event=map_key, value=Aliases, cnt=6\n",
            "prefix=Data.item.Answer.Aliases, event=start_array, value=None, cnt=7\n",
            "prefix=Data.item.Answer.Aliases.item, event=string, value=Presidency of Harry S. Truman, cnt=8\n",
            "prefix=Data.item.Answer.Aliases.item, event=string, value=Hary truman, cnt=9\n",
            "prefix=Data.item.Answer.Aliases.item, event=string, value=Harry Shipp Truman, cnt=10\n",
            "prefix=Data.item.Answer.Aliases.item, event=string, value=HST (president), cnt=20\n",
            "prefix=Data.item.Answer.Aliases.item, event=string, value=Harold Truman, cnt=30\n",
            "prefix=Data.item.Answer.NormalizedAliases.item, event=string, value=truman administration, cnt=40\n",
            "prefix=Data.item.Answer.NormalizedAliases.item, event=string, value=president truman, cnt=50\n",
            "prefix=Data.item.Answer.NormalizedMatchedWikiEntityName, event=string, value=harry s truman, cnt=60\n",
            "prefix=Data.item.Answer, event=end_map, value=None, cnt=67\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using ijson would be one way to approach the data.\n",
        "There seem to be some utilities from when this project was done for how to understand the content of the data files. This needs more exploration."
      ],
      "metadata": {
        "id": "hmy4Ljq8DYo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://github.com/mandarjoshi90/triviaqa/blob/ca43b5820b107f3970cf4b7d67f7db7a98117b79/utils/utils.py#L15\n",
        "def get_file_contents(filename, encoding='utf-8'):\n",
        "    with open(filename, encoding=encoding) as f:\n",
        "        content = f.read()\n",
        "    return content\n",
        "\n",
        "\n",
        "def read_json(filename, encoding='utf-8'):\n",
        "    contents = get_file_contents(filename, encoding=encoding)\n",
        "    return json.loads(contents)\n",
        "\n",
        "\n",
        "def get_file_contents_as_list(file_path, encoding='utf-8', ignore_blanks=True):\n",
        "    contents = get_file_contents(file_path, encoding=encoding)\n",
        "    lines = contents.split('\\n')\n",
        "    lines = [line for line in lines if line != ''] if ignore_blanks else lines\n",
        "    return lines\n",
        "\n",
        "def read_triviaqa_data(qajson):\n",
        "    # data = utils.utils.read_json(qajson)\n",
        "    data = read_json(qajson)\n",
        "    # read only documents and questions that are a part of clean data set\n",
        "    if data['VerifiedEval']:\n",
        "        clean_data = []\n",
        "        for datum in data['Data']:\n",
        "            if datum['QuestionPartOfVerifiedEval']:\n",
        "                if data['Domain'] == 'Web':\n",
        "                    datum = read_clean_part(datum)\n",
        "                clean_data.append(datum)\n",
        "        data['Data'] = clean_data\n",
        "    return data"
      ],
      "metadata": {
        "id": "F6E23sDmJCmK"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}