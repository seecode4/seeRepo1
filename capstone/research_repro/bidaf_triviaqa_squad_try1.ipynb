{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13_3h68fycH01O2QW3dUJ4y0mPYSZNiLo",
      "authorship_tag": "ABX9TyP5rYqTLsFcRhqGe0yKFcvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seecode4/seeRepo1/blob/main/capstone/research_repro/bidaf_triviaqa_squad_try1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capstone Step4 - Try [triviaqa](https://github.com/mandarjoshi90/triviaqa) - BiDAF Model  \n",
        "\n",
        "The BiDAF model used in the paper, [TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension](https://arxiv.org/abs/1705.03551), is based on the original paper for [Bidirectional Attention Flow for Machine Comprehension](https://arxiv.org/abs/1611.01603).  \n",
        "\n",
        "Downloaded SQuAD data and GloVe and nltk corpus. Then followed steps outlined in the related git reference https://github.com/allenai/bi-att-flow/  \n",
        "\n",
        "Got the following and was unable to proceed further.  \n",
        "  W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT  \n",
        "It appears that TensorRT is present but it is unable to access it.\n"
      ],
      "metadata": {
        "id": "pvKLk-7eoy8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://stackoverflow.com/questions/63827064/git-folder-to-google-colab\n",
        "# Decentralized git clone from https://github.com/allenai/bi-att-flow/\n",
        "# Example in https://github.com/fredzett/rmqa/blob/master/S02c_Exercise1.ipynb\n",
        "#   !npx degit fredzett/rmqa/data data\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMK5aXolo6wn",
        "outputId": "364b4d6d-2b2e-477d-ecfa-760c782da801"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Requirements\n",
        "#### General\n",
        "- Python (verified on 3.5.2. Issues have been reported with Python 2!)\n",
        "- unzip, wget (for running `download.sh` only)\n",
        "\n",
        "#### Python Packages\n",
        "- tensorflow (deep learning library, only works on r0.11)\n",
        "- nltk (NLP tools, verified on 3.2.1)\n",
        "- tqdm (progress bar, verified on 4.7.4)\n",
        "- jinja2 (for visaulization; if you only train and test, not needed)\n"
      ],
      "metadata": {
        "id": "J_Rjri7cr9ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "https://github.com/allenai/bi-att-flow/issues/81\n",
        "https://github.com/tensorflow/tensorflow/issues/64809\n",
        "\"\"\"\n",
        "!pip install tensorflow\n",
        "!pip install TensorRT\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG_xg6yaql0y",
        "outputId": "d59823db-a635-4d78-8d4c-d99230d61832"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: TensorRT in /usr/local/lib/python3.10/dist-packages (10.5.0)\n",
            "Requirement already satisfied: tensorrt-cu12==10.5.0 in /usr/local/lib/python3.10/dist-packages (from TensorRT) (10.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://github.com/allenai/bi-att-flow/\n",
        "# NPX is a command-line tool meant to run NPM packages containing CLI scripts.\n",
        "#  if it doesn't work you can always run npm install -g npx\n",
        "#  degit user/repo/subdirectory\n",
        "\n",
        "# Done once and saved to GDrive\n",
        "# !npx degit allenai/bi-att-flow trivia_qa_bidaf_orig"
      ],
      "metadata": {
        "id": "MNOAdCSQBaUB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Click folder icon on left ; mount drive and copy trivia_qa_bidaf_orig to /content/drive/Colab Notebooks\n",
        "!ls\n",
        "# !ls -lrt \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!ls \"/content/drive/MyDrive/GDcc4/ColabNotebooks\"\n",
        "%cd \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone\"\n",
        "!ls -lrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKocQ0uFEeqV",
        "outputId": "1913fc3e-dddc-48e5-87a4-178e3c597213"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "cc4_capstone  cc4_curriculum\n",
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone\n",
            "total 781\n",
            "drwx------  2 root root   4096 Aug 11 22:14 trivia_qa_orig\n",
            "drwx------  2 root root   4096 Aug 12 17:29 see_trivia_qa_try1\n",
            "-rw-------  1 root root    174 Aug 13 18:24 see_trivia_qa_notes.gdoc\n",
            "-rw-------  1 root root   9073 Aug 15 22:33 trivia_qa_read_data.ipynb\n",
            "-rw-------  1 root root  14326 Aug 16 04:14 see_trivia_qa_sample_colors.ipynb\n",
            "-rw-------  1 root root 698468 Aug 17 04:34 see_trivia_qa_read_drive.ipynb\n",
            "drwx------ 10 root root   4096 Aug 18 21:39 trivia_qa_bidaf_orig\n",
            "drwx------  2 root root   4096 Aug 31 01:05 SQuADv1_1\n",
            "-rw-------  1 root root  55823 Oct  8 01:46 trivia_qa_get_entries_ijson.ipynb\n",
            "drwx------  2 root root   4096 Oct  8 22:28 see_notes_save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/allenai/bi-att-flow/blob/master/README.md\n",
        "!cat trivia_qa_bidaf_orig/README.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsSxBuAFFYUR",
        "outputId": "186ba125-34f6-4254-e19d-98b06f4096e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Bi-directional Attention Flow for Machine Comprehension\n",
            " \n",
            "- This the original implementation of [Bi-directional Attention Flow for Machine Comprehension][paper].\n",
            "- The CodaLab worksheet for the [SQuAD Leaderboard][squad] submission is available [here][worksheet].\n",
            "- For TensorFlow v1.2 compatible version, see the [dev][dev] branch.\n",
            "- Please contact [Minjoon Seo][minjoon] ([@seominjoon][minjoon-github]) for questions and suggestions.\n",
            "\n",
            "## 0. Requirements\n",
            "#### General\n",
            "- Python (verified on 3.5.2. Issues have been reported with Python 2!)\n",
            "- unzip, wget (for running `download.sh` only)\n",
            "\n",
            "#### Python Packages\n",
            "- tensorflow (deep learning library, only works on r0.11)\n",
            "- nltk (NLP tools, verified on 3.2.1)\n",
            "- tqdm (progress bar, verified on 4.7.4)\n",
            "- jinja2 (for visaulization; if you only train and test, not needed)\n",
            "\n",
            "## 1. Pre-processing\n",
            "First, prepare data. Donwload SQuAD data and GloVe and nltk corpus\n",
            "(~850 MB, this will download files to `$HOME/data`):\n",
            "```\n",
            "chmod +x download.sh; ./download.sh\n",
            "```\n",
            "\n",
            "Second, Preprocess Stanford QA dataset (along with GloVe vectors) and save them in `$PWD/data/squad` (~5 minutes):\n",
            "```\n",
            "python -m squad.prepro\n",
            "```\n",
            "\n",
            "## 2. Training\n",
            "The model has ~2.5M parameters.\n",
            "The model was trained with NVidia Titan X (Pascal Architecture, 2016).\n",
            "The model requires at least 12GB of GPU RAM.\n",
            "If your GPU RAM is smaller than 12GB, you can either decrease batch size (performance might degrade),\n",
            "or you can use multi GPU (see below).\n",
            "The training converges at ~18k steps, and it took ~4s per step (i.e. ~20 hours).\n",
            "\n",
            "Before training, it is recommended to first try the following code to verify everything is okay and memory is sufficient:\n",
            "```\n",
            "python -m basic.cli --mode train --noload --debug\n",
            "```\n",
            "\n",
            "Then to fully train, run:\n",
            "```\n",
            "python -m basic.cli --mode train --noload\n",
            "```\n",
            "\n",
            "You can speed up the training process with optimization flags:\n",
            "```\n",
            "python -m basic.cli --mode train --noload --len_opt --cluster\n",
            "```\n",
            "You can still omit them, but training will be much slower.\n",
            "\n",
            "Note that during the training, the EM and F1 scores from the occasional evaluation are not the same with the score from official squad evaluation script. \n",
            "The printed scores are not official (our scoring scheme is a bit harsher).\n",
            "To obtain the official number, use the official evaluator (copied in `squad` folder, `squad/evaluate-v1.1.py`). For more information See 3.Test.\n",
            "\n",
            "\n",
            "## 3. Test\n",
            "To test, run:\n",
            "```\n",
            "python -m basic.cli\n",
            "```\n",
            "\n",
            "Similarly to training, you can give the optimization flags to speed up test (5 minutes on dev data):\n",
            "```\n",
            "python -m basic.cli --len_opt --cluster\n",
            "```\n",
            "\n",
            "This command loads the most recently saved model during training and begins testing on the test data.\n",
            "After the process ends, it prints F1 and EM scores, and also outputs a json file (`$PWD/out/basic/00/answer/test-####.json`,\n",
            "where `####` is the step # that the model was saved).\n",
            "Note that the printed scores are not official (our scoring scheme is a bit harsher).\n",
            "To obtain the official number, use the official evaluator (copied in `squad` folder) and the output json file:\n",
            "\n",
            "```\n",
            "python squad/evaluate-v1.1.py $HOME/data/squad/dev-v1.1.json out/basic/00/answer/test-####.json\n",
            "```\n",
            "\n",
            "### 3.1 Loading from pre-trained weights\n",
            "Instead of training the model yourself, you can choose to use pre-trained weights that were used for [SQuAD Leaderboard][squad] submission.\n",
            "Refer to [this worksheet][worksheet] in CodaLab to reproduce the results.\n",
            "If you are unfamiliar with CodaLab, follow these simple steps (given that you met all prereqs above):\n",
            "\n",
            "1. Download `save.zip` from the [worksheet][worksheet] and unzip it in the current directory.\n",
            "2. Copy `glove.6B.100d.txt` from your glove data folder (`$HOME/data/glove/`) to the current directory.\n",
            "3. To reproduce single model:\n",
            "  \n",
            "  ```\n",
            "  basic/run_single.sh $HOME/data/squad/dev-v1.1.json single.json\n",
            "  ```\n",
            "  \n",
            "  This writes the answers to `single.json` in the current directory. You can then use the official evaluator to obtain EM and F1 scores. If you want to run on GPU (~5 mins), change the value of batch_size flag in the shell file to a higher number (60 for 12GB GPU RAM). \n",
            "4. Similarly, to reproduce ensemble method:\n",
            "  \n",
            "  ```\n",
            "  basic/run_ensemble.sh $HOME/data/squad/dev-v1.1.json ensemble.json \n",
            "  ```\n",
            "  If you want to run on GPU, you should run the script sequentially by removing '&' in the forloop, or you will need to specify different GPUs for each run of the for loop.\n",
            "\n",
            "## Results\n",
            "\n",
            "### Dev Data\n",
            "\n",
            "Note these scores are from the official evaluator (copied in `squad` folder, `squad/evaluate-v1.1.py`). For more information See 3.Test.\n",
            "The scores appeared during the training could be lower than the scores from the official evaluator. \n",
            "\n",
            "|          | EM (%) | F1 (%) |\n",
            "| -------- |:------:|:------:|\n",
            "| single   | 67.7   | 77.3   |\n",
            "| ensemble | 72.6   | 80.7   |\n",
            "\n",
            "### Test Data\n",
            "\n",
            "|          | EM (%) | F1 (%) |\n",
            "| -------- |:------:|:------:|\n",
            "| single   | 68.0   | 77.3   |\n",
            "| ensemble | 73.3   | 81.1   |\n",
            "\n",
            "Refer to [our paper][paper] for more details.\n",
            "See [SQuAD Leaderboard][squad] to compare with other models.\n",
            "\n",
            "\n",
            "<!--\n",
            "## Using Pre-trained Model\n",
            "\n",
            "If you would like to use pre-trained model, it's very easy! \n",
            "You can download the model weights [here][save] (make sure that its commit id matches the source code's).\n",
            "Extract them and put them in `$PWD/out/basic/00/save` directory, with names unchanged.\n",
            "Then do the testing again, but you need to specify the step # that you are loading from:\n",
            "```\n",
            "python -m basic.cli --mode test --batch_size 8 --eval_num_batches 0 --load_step ####\n",
            "```\n",
            "-->\n",
            "\n",
            "\n",
            "## Multi-GPU Training & Testing\n",
            "Our model supports multi-GPU training.\n",
            "We follow the parallelization paradigm described in [TensorFlow Tutorial][multi-gpu].\n",
            "In short, if you want to use batch size of 60 (default) but if you have 3 GPUs with 4GB of RAM,\n",
            "then you initialize each GPU with batch size of 20, and combine the gradients on CPU.\n",
            "This can be easily done by running:\n",
            "```\n",
            "python -m basic.cli --mode train --noload --num_gpus 3 --batch_size 20\n",
            "```\n",
            "\n",
            "Similarly, you can speed up your testing by:\n",
            "```\n",
            "python -m basic.cli --num_gpus 3 --batch_size 20 \n",
            "```\n",
            "\n",
            "## Demo\n",
            "For now, please refer to the `demo` branch of this repository.\n",
            " \n",
            "\n",
            "[multi-gpu]: https://www.tensorflow.org/versions/r0.11/tutorials/deep_cnn/index.html#training-a-model-using-multiple-gpu-cards\n",
            "[squad]: http://stanford-qa.com\n",
            "[paper]: https://arxiv.org/abs/1611.01603\n",
            "[worksheet]: https://worksheets.codalab.org/worksheets/0x37a9b8c44f6845c28866267ef941c89d/\n",
            "[minjoon]: https://seominjoon.github.io\n",
            "[minjoon-github]: https://github.com/seominjoon\n",
            "[dev]: https://github.com/allenai/bi-att-flow/tree/dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Go to directory to try\n",
        "!pwd\n",
        "!ls -lrt trivia_qa_bidaf_orig\n",
        "%cd trivia_qa_bidaf_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlAhdqnrFyfc",
        "outputId": "4a646961-c56c-452b-d47e-6cfaa719ddc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone\n",
            "total 60\n",
            "-rw------- 1 root root    33 Jan 25  2018  requirements.txt\n",
            "-rw------- 1 root root  6576 Jan 25  2018  README.md\n",
            "-rw------- 1 root root 11358 Jan 25  2018  LICENSE\n",
            "-rw------- 1 root root   695 Jan 25  2018  download.sh\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  visualization\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  tree\n",
            "drwx------ 3 root root  4096 Aug 18 21:39  squad\n",
            "drwx------ 5 root root  4096 Aug 18 21:39  my\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  cnn_dm\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  basic_cnn\n",
            "drwx------ 4 root root  4096 Aug 18 21:39  basic\n",
            "-rw------- 1 root root  7757 Aug 18 22:54 'Copy of nn.py'\n",
            "drwx------ 5 root root  4096 Oct  9 00:31  data\n",
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls -lrt\n",
        "print(\"!ls -lrt data\")\n",
        "!ls -lrt data\n",
        "print(\"!ls -lrt data/squad\")\n",
        "!ls -lrt data/squad\n",
        "print(\"!du -hs data/squad\")\n",
        "!du -hs data/squad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbHEGo71iXW8",
        "outputId": "1c863e52-3582-4b24-84da-5b5b01125912"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "total 60\n",
            "-rw------- 1 root root    33 Jan 25  2018  requirements.txt\n",
            "-rw------- 1 root root  6576 Jan 25  2018  README.md\n",
            "-rw------- 1 root root 11358 Jan 25  2018  LICENSE\n",
            "-rw------- 1 root root   695 Jan 25  2018  download.sh\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  visualization\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  tree\n",
            "drwx------ 3 root root  4096 Aug 18 21:39  squad\n",
            "drwx------ 5 root root  4096 Aug 18 21:39  my\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  cnn_dm\n",
            "drwx------ 2 root root  4096 Aug 18 21:39  basic_cnn\n",
            "drwx------ 4 root root  4096 Aug 18 21:39  basic\n",
            "-rw------- 1 root root  7757 Aug 18 22:54 'Copy of nn.py'\n",
            "drwx------ 5 root root  4096 Oct  9 00:31  data\n",
            "!ls -lrt data\n",
            "total 13\n",
            "-rw------- 1 root root  207 Oct  9 00:31 readme.txt\n",
            "drwx------ 2 root root 4096 Oct  9 00:31 glove\n",
            "drwx------ 2 root root 4096 Oct  9 00:31 squad_1_1\n",
            "drwx------ 2 root root 4096 Oct  9 01:16 squad\n",
            "!ls -lrt data/squad\n",
            "total 400074\n",
            "-rw------- 1 root root  43607526 Oct  9 01:13 data_train.json\n",
            "-rw------- 1 root root 240091238 Oct  9 01:14 shared_train.json\n",
            "-rw------- 1 root root   6488675 Oct  9 01:15 data_dev.json\n",
            "-rw------- 1 root root  56498701 Oct  9 01:15 shared_dev.json\n",
            "-rw------- 1 root root   6488675 Oct  9 01:15 data_test.json\n",
            "-rw------- 1 root root  56498701 Oct  9 01:16 shared_test.json\n",
            "!du -hs data/squad\n",
            "391M\tdata/squad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $HOME\n",
        "!echo $PWD\n",
        "print(\"ls /root\")\n",
        "!ls /root\n",
        "!pwd\n",
        "!ls ../SQuADv1_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjUY1YlS98Ag",
        "outputId": "9b666185-85f7-4c1f-e829-00da4e11aba0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "ls /root\n",
            "data  nltk_data\n",
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "readme_sk.txt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "## 1. Pre-processing - skip data is in GDrive cc4_capstone/data_local\n",
        "# First, prepare data. Donwload SQuAD data and GloVe and nltk corpus\n",
        "# (~850 MB, this will download files to `$HOME/data`):\n",
        "# !chmod +x download.sh\n",
        "# !./download.sh\n",
        "!cat ./download.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_T_J_OPi-jZ",
        "outputId": "0053c1b7-1c12-4fcd-cec8-981bd71d246d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env bash\n",
            "\n",
            "DATA_DIR=$HOME/data\n",
            "mkdir $DATA_DIR\n",
            "\n",
            "# Download SQuAD\n",
            "SQUAD_DIR=$DATA_DIR/squad\n",
            "mkdir $SQUAD_DIR\n",
            "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json -O $SQUAD_DIR/train-v1.1.json\n",
            "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json -O $SQUAD_DIR/dev-v1.1.json\n",
            "\n",
            "\n",
            "# Download CNN and DailyMail\n",
            "# Download at: http://cs.nyu.edu/~kcho/DMQA/\n",
            "\n",
            "\n",
            "# Download GloVe\n",
            "GLOVE_DIR=$DATA_DIR/glove\n",
            "mkdir $GLOVE_DIR\n",
            "wget http://nlp.stanford.edu/data/glove.6B.zip -O $GLOVE_DIR/glove.6B.zip\n",
            "unzip $GLOVE_DIR/glove.6B.zip -d $GLOVE_DIR\n",
            "\n",
            "# Download NLTK (for tokenizer)\n",
            "# Make sure that nltk is installed!\n",
            "python3 -m nltk.downloader -d $HOME/nltk_data punkt\n",
            "CPU times: user 4.67 ms, sys: 1.09 ms, total: 5.77 ms\n",
            "Wall time: 103 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved to local GDrive # Download GloVe\n",
        "!pwd\n",
        "!ls data/glove\n",
        "!echo wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip -O data/glove/glove.6B.zip > data/glove/readme.txt\n",
        "# !wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip -O data/glove/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rgdAP64o_re",
        "outputId": "4a33fbcf-d3b7-479f-d5a5-4d397fafec30"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "glove.6B.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved to local GDrive # Download SQuAD\n",
        "!echo wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json -O data/squad_1_1/train-v1.1.json >> data/glove/readme.txt\n",
        "!echo wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json -O data/squad_1_/dev-v1.1.json >> data/glove/readme.txt\n",
        "!mv data/glove/readme.txt data/readme.txt\n",
        "!cat data/readme.txt\n",
        "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json -O data/squad_1_1/train-v1.1.json\n",
        "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json -O data/squad_1_1/dev-v1.1.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMxSeWekrHma",
        "outputId": "dcc8e192-79ce-4f0f-c612-5deeed596dd7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip -O data/glove/glove.6B.zip\n",
            "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json -O data/squad_1_1/train-v1.1.json\n",
            "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json -O data/squad_1_/dev-v1.1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lrt data/glove data/squad_1_1\n",
        "!echo $HOME\n",
        "!echo $HOME/data\n",
        "# !mkdir -p /root/data/squad /root/data/glove\n",
        "# !ls /root/data/{squad,glove}\n",
        "# !cp -p data/squad_1_1/* /root/data/squad\n",
        "# !cp -p data/glove/* /root/data/glove\n",
        "# !unzip /root/data/glove/glove.6B.zip -d /root/data/glove\n",
        "!ls -lrt /root/data/{squad,glove}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcj9gFmSseWl",
        "outputId": "44536baf-650b-4518-81ec-3466515af783"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/squad_1_1:\n",
            "total 34320\n",
            "-rw------- 1 root root 30288272 Oct 13  2023 train-v1.1.json\n",
            "-rw------- 1 root root  4854279 Oct 13  2023 dev-v1.1.json\n",
            "\n",
            "data/glove:\n",
            "total 841976\n",
            "-rw------- 1 root root 862182613 Oct 25  2015 glove.6B.zip\n",
            "/root\n",
            "/root/data\n",
            "/root/data/squad:\n",
            "total 34324\n",
            "-rw------- 1 root root 30288272 Oct 13  2023 train-v1.1.json\n",
            "-rw------- 1 root root  4854279 Oct 13  2023 dev-v1.1.json\n",
            "\n",
            "/root/data/glove:\n",
            "total 3039132\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw------- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK (for tokenizer)\n",
        "import nltk\n",
        "# dir(nltk)\n",
        "# !python3 -m nltk.downloader -d $HOME/nltk_data punkt - skip this\n",
        "nltk.download('punkt', download_dir='/root/nltk_data')\n",
        "!ls -lrt /root /root/data /root/nltk_data/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdHoh_TvttJc",
        "outputId": "bb2dbcf6-2102-4952-8d31-8220e45a7707"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/data:\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Oct  9 01:00 squad\n",
            "drwxr-xr-x 2 root root 4096 Oct  9 01:03 glove\n",
            "\n",
            "/root/nltk_data/tokenizers:\n",
            "total 13584\n",
            "-rw-r--r-- 1 root root 13905355 Oct  9 01:07 punkt.zip\n",
            "drwxr-xr-x 3 root root     4096 Oct  9 01:08 punkt\n",
            "\n",
            "/root:\n",
            "total 8\n",
            "drwxr-xr-x 4 root root 4096 Oct  9 00:42 data\n",
            "drwxr-xr-x 3 root root 4096 Oct  9 01:07 nltk_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes from first try of download.sh - copies data to /root\n",
        "--2024-08-19 23:09:42--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
        "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
        "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
        "HTTP request sent, awaiting response... 200 OK\n",
        "Length: 30288272 (29M) [application/json]\n",
        "Saving to: ‘/root/data/squad/train-v1.1.json’\n",
        "\n",
        "/root/data/squad/tr 100%[===================>]  28.88M   171MB/s    in 0.2s    \n",
        "\n",
        "2024-08-19 23:09:43 (171 MB/s) - ‘/root/data/squad/train-v1.1.json’ saved [30288272/30288272]\n",
        "\n",
        "--2024-08-19 23:09:43--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
        "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
        "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
        "HTTP request sent, awaiting response... 200 OK\n",
        "Length: 4854279 (4.6M) [application/json]\n",
        "Saving to: ‘/root/data/squad/dev-v1.1.json’\n",
        "\n",
        "/root/data/squad/de 100%[===================>]   4.63M  --.-KB/s    in 0.09s   \n",
        "\n",
        "2024-08-19 23:09:43 (53.1 MB/s) - ‘/root/data/squad/dev-v1.1.json’ saved [4854279/4854279]\n",
        "\n",
        "--2024-08-19 23:09:43--  http://nlp.stanford.edu/data/glove.6B.zip\n",
        "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
        "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
        "HTTP request sent, awaiting response... 302 Found\n",
        "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
        "--2024-08-19 23:09:43--  https://nlp.stanford.edu/data/glove.6B.zip\n",
        "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
        "HTTP request sent, awaiting response... 301 Moved Permanently\n",
        "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
        "--2024-08-19 23:09:44--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
        "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
        "HTTP request sent, awaiting response... 200 OK\n",
        "Length: 862182613 (822M) [application/zip]\n",
        "Saving to: ‘/root/data/glove/glove.6B.zip’\n",
        "\n",
        "/root/data/glove/gl 100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
        "\n",
        "2024-08-19 23:12:23 (5.18 MB/s) - ‘/root/data/glove/glove.6B.zip’ saved [862182613/862182613]\n",
        "\n",
        "Archive:  /root/data/glove/glove.6B.zip\n",
        "  inflating: /root/data/glove/glove.6B.50d.txt  \n",
        "  inflating: /root/data/glove/glove.6B.100d.txt  \n",
        "  inflating: /root/data/glove/glove.6B.200d.txt  \n",
        "  inflating: /root/data/glove/glove.6B.300d.txt  \n",
        "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
        "  warn(RuntimeWarning(msg))\n",
        "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
        "[nltk_data]   Unzipping tokenizers/punkt.zip."
      ],
      "metadata": {
        "id": "ojV_bLsTOQk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"!ls /root\")\n",
        "!ls /root\n",
        "print(\"\\n!ls /root/data\")\n",
        "!ls /root/data\n",
        "print(\"\\n!ls /root/nltk_data\")\n",
        "!ls /root/nltk_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IVkuU38jMAx",
        "outputId": "c21c6423-dfc8-4441-dbe8-add1f910d75a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!ls /root\n",
            "data  nltk_data\n",
            "\n",
            "!ls /root/data\n",
            "glove  squad\n",
            "\n",
            "!ls /root/nltk_data\n",
            "tokenizers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "#!mv ./data /root\n",
        "# Note squad.prepro expect train-v1.1.json etc in /root/data\n",
        "!echo $PWD\n",
        "!ls -l /root/data/squad\n",
        "!du -hs /root/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRR0bW8Ckfms",
        "outputId": "37a393b3-dd07-4517-a044-a597e937f339"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "total 34324\n",
            "-rw------- 1 root root  4854279 Oct 13  2023 dev-v1.1.json\n",
            "-rw------- 1 root root 30288272 Oct 13  2023 train-v1.1.json\n",
            "3.0G\t/root/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Second, Preprocess Stanford QA dataset (along with GloVe vectors) and\n",
        "# save them in `$PWD/data/squad` (~5 minutes):\n",
        "!pwd\n",
        "!ls -lrt /root/data\n",
        "!ls -lrt /root/data/glove\n",
        "!ls -lrt /root/data/squad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCu-LrsGkzDt",
        "outputId": "a194ec51-540e-44f7-ea2d-1169ce8dc055"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Oct  9 01:00 squad\n",
            "drwxr-xr-x 2 root root 4096 Oct  9 01:03 glove\n",
            "total 3039132\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw------- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "total 34324\n",
            "-rw------- 1 root root 30288272 Oct 13  2023 train-v1.1.json\n",
            "-rw------- 1 root root  4854279 Oct 13  2023 dev-v1.1.json\n",
            "CPU times: user 20.1 ms, sys: 3.16 ms, total: 23.3 ms\n",
            "Wall time: 432 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Second, Preprocess Stanford QA dataset (along with GloVe vectors) and\n",
        "# save them in `$PWD/data/squad` (~5 minutes):\n",
        "!pwd\n",
        "!python -m squad.prepro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EBplGR_ogUf",
        "outputId": "2eb9e28c-cc31-4c57-b3c9-43de728407ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig\n",
            "100% 442/442 [01:17<00:00,  5.73it/s]\n",
            "100% 400000/400000 [00:07<00:00, 53448.11it/s]\n",
            "69844/103462 of word vocab have corresponding vectors in /root/data/glove/glove.6B.100d.txt\n",
            "100% 400000/400000 [00:09<00:00, 43275.01it/s]\n",
            "70717/90346 of word vocab have corresponding vectors in /root/data/glove/glove.6B.100d.txt\n",
            "saving ...\n",
            "100% 48/48 [00:17<00:00,  2.71it/s]\n",
            "100% 400000/400000 [00:08<00:00, 48638.20it/s]\n",
            "22749/28017 of word vocab have corresponding vectors in /root/data/glove/glove.6B.100d.txt\n",
            "100% 400000/400000 [00:10<00:00, 36427.81it/s]\n",
            "22905/24914 of word vocab have corresponding vectors in /root/data/glove/glove.6B.100d.txt\n",
            "saving ...\n",
            "100% 48/48 [00:15<00:00,  3.05it/s]\n",
            "100% 400000/400000 [00:09<00:00, 43929.86it/s]\n",
            "22749/28017 of word vocab have corresponding vectors in /root/data/glove/glove.6B.100d.txt\n",
            "100% 400000/400000 [00:06<00:00, 57548.88it/s]\n",
            "22905/24914 of word vocab have corresponding vectors in /root/data/glove/glove.6B.100d.txt\n",
            "saving ...\n",
            "CPU times: user 2.04 s, sys: 223 ms, total: 2.26 s\n",
            "Wall time: 3min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lrt /root/data\n",
        "!ls -lrt /root/data/glove\n",
        "!ls -lrt /root/data/squad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ztEKxwn7TU",
        "outputId": "66693759-825f-4cc9-8e4d-f66d7d9c3256"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Oct  9 01:00 squad\n",
            "drwxr-xr-x 2 root root 4096 Oct  9 01:03 glove\n",
            "total 3039132\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw------- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "total 34324\n",
            "-rw------- 1 root root 30288272 Oct 13  2023 train-v1.1.json\n",
            "-rw------- 1 root root  4854279 Oct 13  2023 dev-v1.1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training\n",
        "The model has ~2.5M parameters.\n",
        "The model was trained with NVidia Titan X (Pascal Architecture, 2016).\n",
        "The model requires at least 12GB of GPU RAM.\n",
        "If your GPU RAM is smaller than 12GB, you can either decrease batch size (performance might degrade),\n",
        "or you can use multi GPU (see below).\n",
        "The training converges at ~18k steps, and it took ~4s per step (i.e. ~20 hours).\n",
        "\n",
        "Before training, it is recommended to first try the following code to verify everything is okay and memory is sufficient:\n",
        "```\n",
        "python -m basic.cli --mode train --noload --debug\n",
        "```"
      ],
      "metadata": {
        "id": "pxwQ5-tinEDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://github.com/tensorflow/tensorflow/issues/64809\n",
        "# https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html\n",
        "# !python -c \"import tensorrt; print(tensorrt.__file__)\"\n",
        "# !python -c \"import tensorflow as tf; print(tf.config.list_physical_devices())\"\n",
        "!python -c \"import tensorrt; print(dir(tensorrt), '\\n', tensorrt.__version__)\"\n",
        "help_dir_tensorrt = ['APILanguage', 'ActivationType', 'AllocatorFlag',\n",
        "                      'BoundingBoxFormat', 'Builder', 'BuilderFlag',\n",
        "                      'CalibrationAlgoType', 'DataType', 'DeviceType',\n",
        "                      'DimensionOperation', 'Dims', 'Dims2', 'Dims3', 'Dims4',\n",
        "                      'DimsExprs', 'DimsHW', 'DynamicPluginTensorDesc',\n",
        "                      'ElementWiseOperation', 'EngineCapability', 'EngineInspector',\n",
        "                      'ErrorCode', 'ErrorCodeTRT', 'ExecutionContextAllocationStrategy',\n",
        "                      'FallbackString', 'FillOperation', 'GatherMode', 'HardwareCompatibilityLevel',\n",
        "                      'IActivationLayer', 'IAlgorithm', 'IAlgorithmContext', 'IAlgorithmIOInfo',\n",
        "                      'IAlgorithmSelector', 'IAlgorithmVariant', 'IAssertionLayer', 'IBuilderConfig',\n",
        "                      'ICastLayer', 'IConcatenationLayer', 'IConditionLayer', 'IConstantLayer', 'IConvolutionLayer',\n",
        "                      'ICudaEngine', 'IDebugListener', 'IDeconvolutionLayer', 'IDequantizeLayer', 'IDimensionExpr',\n",
        "                      'IEinsumLayer', 'IElementWiseLayer', 'IErrorRecorder', 'IExecutionContext', 'IExprBuilder',\n",
        "                      'IFillLayer', 'IGatherLayer', 'IGpuAllocator', 'IGpuAsyncAllocator', 'IGridSampleLayer',\n",
        "                      'IHostMemory', 'IIdentityLayer', 'IIfConditional', 'IIfConditionalBoundaryLayer',\n",
        "                      'IIfConditionalInputLayer', 'IIfConditionalOutputLayer', 'IInt8Calibrator',\n",
        "                      'IInt8EntropyCalibrator', 'IInt8EntropyCalibrator2', 'IInt8LegacyCalibrator',\n",
        "                      'IInt8MinMaxCalibrator', 'IIteratorLayer', 'ILRNLayer', 'ILayer', 'ILogger',\n",
        "                      'ILoop', 'ILoopBoundaryLayer', 'ILoopOutputLayer', 'IMatrixMultiplyLayer', 'INMSLayer',\n",
        "                      'INetworkDefinition', 'INonZeroLayer', 'INormalizationLayer', 'IOneHotLayer', 'IOptimizationProfile',\n",
        "                      'IOutputAllocator', 'IPaddingLayer', 'IParametricReLULayer', 'IPluginCapability', 'IPluginCreator',\n",
        "                      'IPluginCreatorInterface', 'IPluginCreatorV3One', 'IPluginRegistry', 'IPluginResource',\n",
        "                      'IPluginResourceContext', 'IPluginV2', 'IPluginV2DynamicExt', 'IPluginV2DynamicExtBase',\n",
        "                      'IPluginV2Ext', 'IPluginV2Layer', 'IPluginV3', 'IPluginV3Layer', 'IPluginV3OneBuild',\n",
        "                      'IPluginV3OneBuildV2', 'IPluginV3OneCore', 'IPluginV3OneRuntime', 'IPoolingLayer', 'IProfiler',\n",
        "                      'IProgressMonitor', 'IQuantizeLayer', 'IRaggedSoftMaxLayer', 'IRecurrenceLayer', 'IReduceLayer',\n",
        "                      'IResizeLayer', 'IReverseSequenceLayer', 'IScaleLayer', 'IScatterLayer', 'ISelectLayer',\n",
        "                      'ISerializationConfig', 'IShapeLayer', 'IShuffleLayer', 'ISliceLayer', 'ISoftMaxLayer',\n",
        "                      'IStreamReader', 'ITensor', 'ITimingCache', 'ITopKLayer', 'ITripLimitLayer', 'IUnaryLayer',\n",
        "                      'IVersionedInterface', 'InterfaceInfo', 'InterpolationMode', 'LayerInformationFormat',\n",
        "                      'LayerType', 'Logger', 'LoopOutput', 'MatrixOperation', 'MemoryPoolType',\n",
        "                      'NetworkDefinitionCreationFlag', 'NodeIndices', 'OnnxParser', 'OnnxParserFlag',\n",
        "                      'OnnxParserRefitter', 'PaddingMode', 'ParserError', 'Permutation',\n",
        "                      'PluginCapabilityType', 'PluginCreatorVersion', 'PluginField', 'PluginFieldCollection',\n",
        "                      'PluginFieldCollection_', 'PluginFieldType', 'PluginTensorDesc', 'PoolingType', 'PreviewFeature',\n",
        "                      'Profiler', 'ProfilingVerbosity', 'QuantizationFlag', 'ReduceOperation', 'Refitter',\n",
        "                      'ResizeCoordinateTransformation', 'ResizeRoundMode', 'ResizeSelector', 'Runtime',\n",
        "                      'RuntimePlatform', 'SampleMode', 'ScaleMode', 'ScatterMode', 'SerializationFlag',\n",
        "                      'SubGraphCollection', 'TacticSource', 'TempfileControlFlag',\n",
        "                      'TensorFormat', 'TensorIOMode', 'TensorLocation', 'TensorRTPhase',\n",
        "                      'TopKOperation', 'TripLimit', 'UnaryOperation', 'Weights', 'WeightsRole',\n",
        "                      '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__',\n",
        "                      '__package__', '__path__', '__spec__', '__version__', 'attr', 'bfloat16', 'bool',\n",
        "                      'common_enter', 'common_exit', 'ctypes', 'float16', 'float32', 'fp8', 'get_builder_plugin_registry',\n",
        "                      'get_nv_onnx_parser_version', 'get_plugin_registry', 'init_libnvinfer_plugins',\n",
        "                      'int32', 'int4', 'int64', 'int8', 'nptype', 'os', 'sys',\n",
        "                      'tensorrt', 'tensorrt_libs', 'uint8', 'value', 'volume', 'warnings']\n",
        "import tensorflow as tf\n",
        "import tensorrt\n",
        "print(tf.config.list_physical_devices())\n",
        "print(tensorrt.__file__)\n",
        "print(\"tensorflow ver:\", tf.__version__)\n",
        "print(\"TensorRT ver:\", tensorrt.__version__)\n",
        "print(\"cuda ver:\")\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oTiG8UT12I1",
        "outputId": "bb471285-27de-4252-b2bd-f6359bf66fca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['APILanguage', 'ActivationType', 'AllocatorFlag', 'BoundingBoxFormat', 'Builder', 'BuilderFlag', 'CalibrationAlgoType', 'DataType', 'DeviceType', 'DimensionOperation', 'Dims', 'Dims2', 'Dims3', 'Dims4', 'DimsExprs', 'DimsHW', 'DynamicPluginTensorDesc', 'ElementWiseOperation', 'EngineCapability', 'EngineInspector', 'ErrorCode', 'ErrorCodeTRT', 'ExecutionContextAllocationStrategy', 'FallbackString', 'FillOperation', 'GatherMode', 'HardwareCompatibilityLevel', 'IActivationLayer', 'IAlgorithm', 'IAlgorithmContext', 'IAlgorithmIOInfo', 'IAlgorithmSelector', 'IAlgorithmVariant', 'IAssertionLayer', 'IBuilderConfig', 'ICastLayer', 'IConcatenationLayer', 'IConditionLayer', 'IConstantLayer', 'IConvolutionLayer', 'ICudaEngine', 'IDebugListener', 'IDeconvolutionLayer', 'IDequantizeLayer', 'IDimensionExpr', 'IEinsumLayer', 'IElementWiseLayer', 'IErrorRecorder', 'IExecutionContext', 'IExprBuilder', 'IFillLayer', 'IGatherLayer', 'IGpuAllocator', 'IGpuAsyncAllocator', 'IGridSampleLayer', 'IHostMemory', 'IIdentityLayer', 'IIfConditional', 'IIfConditionalBoundaryLayer', 'IIfConditionalInputLayer', 'IIfConditionalOutputLayer', 'IInt8Calibrator', 'IInt8EntropyCalibrator', 'IInt8EntropyCalibrator2', 'IInt8LegacyCalibrator', 'IInt8MinMaxCalibrator', 'IIteratorLayer', 'ILRNLayer', 'ILayer', 'ILogger', 'ILoop', 'ILoopBoundaryLayer', 'ILoopOutputLayer', 'IMatrixMultiplyLayer', 'INMSLayer', 'INetworkDefinition', 'INonZeroLayer', 'INormalizationLayer', 'IOneHotLayer', 'IOptimizationProfile', 'IOutputAllocator', 'IPaddingLayer', 'IParametricReLULayer', 'IPluginCapability', 'IPluginCreator', 'IPluginCreatorInterface', 'IPluginCreatorV3One', 'IPluginRegistry', 'IPluginResource', 'IPluginResourceContext', 'IPluginV2', 'IPluginV2DynamicExt', 'IPluginV2DynamicExtBase', 'IPluginV2Ext', 'IPluginV2Layer', 'IPluginV3', 'IPluginV3Layer', 'IPluginV3OneBuild', 'IPluginV3OneBuildV2', 'IPluginV3OneCore', 'IPluginV3OneRuntime', 'IPoolingLayer', 'IProfiler', 'IProgressMonitor', 'IQuantizeLayer', 'IRaggedSoftMaxLayer', 'IRecurrenceLayer', 'IReduceLayer', 'IResizeLayer', 'IReverseSequenceLayer', 'IScaleLayer', 'IScatterLayer', 'ISelectLayer', 'ISerializationConfig', 'IShapeLayer', 'IShuffleLayer', 'ISliceLayer', 'ISoftMaxLayer', 'IStreamReader', 'ITensor', 'ITimingCache', 'ITopKLayer', 'ITripLimitLayer', 'IUnaryLayer', 'IVersionedInterface', 'InterfaceInfo', 'InterpolationMode', 'LayerInformationFormat', 'LayerType', 'Logger', 'LoopOutput', 'MatrixOperation', 'MemoryPoolType', 'NetworkDefinitionCreationFlag', 'NodeIndices', 'OnnxParser', 'OnnxParserFlag', 'OnnxParserRefitter', 'PaddingMode', 'ParserError', 'Permutation', 'PluginCapabilityType', 'PluginCreatorVersion', 'PluginField', 'PluginFieldCollection', 'PluginFieldCollection_', 'PluginFieldType', 'PluginTensorDesc', 'PoolingType', 'PreviewFeature', 'Profiler', 'ProfilingVerbosity', 'QuantizationFlag', 'ReduceOperation', 'Refitter', 'ResizeCoordinateTransformation', 'ResizeRoundMode', 'ResizeSelector', 'Runtime', 'RuntimePlatform', 'SampleMode', 'ScaleMode', 'ScatterMode', 'SerializationFlag', 'SubGraphCollection', 'TacticSource', 'TempfileControlFlag', 'TensorFormat', 'TensorIOMode', 'TensorLocation', 'TensorRTPhase', 'TopKOperation', 'TripLimit', 'UnaryOperation', 'Weights', 'WeightsRole', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'attr', 'bfloat16', 'bool', 'common_enter', 'common_exit', 'ctypes', 'float16', 'float32', 'fp8', 'get_builder_plugin_registry', 'get_nv_onnx_parser_version', 'get_plugin_registry', 'init_libnvinfer_plugins', 'int32', 'int4', 'int64', 'int8', 'nptype', 'os', 'sys', 'tensorrt', 'tensorrt_libs', 'uint8', 'value', 'volume', 'warnings'] \n",
            " 10.5.0\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "/usr/local/lib/python3.10/dist-packages/tensorrt/__init__.py\n",
            "tensorflow ver: 2.17.0\n",
            "TensorRT ver: 10.5.0\n",
            "cuda ver:\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Wed Oct  9 01:53:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "!pip install nvidia-tensorrt\n",
        "# Restart Runtime: After installation, restart your Colab runtime to apply changes.\n",
        "# Enable TF-TRT optimization\n",
        "tf.config.optimizer.set_experimental_options({\"tf_trt_enable_native_ops\": True})\n",
        "!dpkg -l | grep nvidiatensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g7dyujs5bHF",
        "outputId": "2833fb61-8d28-4c43-de7b-cfed3034a589"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvidia-tensorrt in /usr/local/lib/python3.10/dist-packages (99.0.0)\n",
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (from nvidia-tensorrt) (10.5.0)\n",
            "Requirement already satisfied: tensorrt-cu12==10.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt->nvidia-tensorrt) (10.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dir(tf)\n",
        "!which python\n",
        "!ls /usr/local/bin/t*\n",
        "# !strace -e open,openat python -c \"import tensorflow as tf\" 2>&1 | grep \"libnvinfer\\|TF-TRT\"\n",
        "!dpkg -l | grep nvinfer\n",
        "!pip install --upgrade --index-url https://pypi.ngc.nvidia.com nvidia-tensorrt\n",
        "import tensorrt as trt\n",
        "print(trt.__version__)\n",
        "note=\"\"\"\n",
        "Looking in indexes: https://pypi.ngc.nvidia.com\n",
        "Requirement already satisfied: nvidia-tensorrt in /usr/local/lib/python3.10/dist-packages (99.0.0)\n",
        "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (from nvidia-tensorrt) (10.5.0)\n",
        "Requirement already satisfied: tensorrt-cu12==10.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt->nvidia-tensorrt) (10.5.0)\n",
        "10.5.0\n",
        "\"\"\"\n",
        "import os\n",
        "print(os.environ['LD_LIBRARY_PATH'])\n",
        "# Add the directory to the LD_LIBRARY_PATH\n",
        "os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia:/usr/local/lib/python3.10/dist-packages/tensorrt_libs'\n",
        "print(os.environ['LD_LIBRARY_PATH'])\n",
        "!echo $LD_LIBRARY_PATH\n",
        "# !ls /usr/local/lib/python3.10/dist-packages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "911NUU2etCYo",
        "outputId": "c93b17f6-47e8-4d33-9306-5af6bd716e21"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n",
            "/usr/local/bin/tabulate\t\t      /usr/local/bin/tifffile\n",
            "/usr/local/bin/tb-gcp-uploader\t      /usr/local/bin/toco\n",
            "/usr/local/bin/tensorboard\t      /usr/local/bin/toco_from_protos\n",
            "/usr/local/bin/test-importability.py  /usr/local/bin/torchrun\n",
            "/usr/local/bin/tfds\t\t      /usr/local/bin/tqdm\n",
            "/usr/local/bin/tflite_convert\t      /usr/local/bin/transformers-cli\n",
            "/usr/local/bin/tf_upgrade_v2\t      /usr/local/bin/ttx\n",
            "/usr/local/bin/tiff2fsspec\t      /usr/local/bin/typer\n",
            "/usr/local/bin/tiffcomment\n",
            "Looking in indexes: https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: nvidia-tensorrt in /usr/local/lib/python3.10/dist-packages (99.0.0)\n",
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (from nvidia-tensorrt) (10.5.0)\n",
            "Requirement already satisfied: tensorrt-cu12==10.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt->nvidia-tensorrt) (10.5.0)\n",
            "10.5.0\n",
            "/usr/lib64-nvidia:/usr/local/lib/python3.10/dist-packages\n",
            "/usr/lib64-nvidia:/usr/local/lib/python3.10/dist-packages/tensorrt_libs\n",
            "/usr/lib64-nvidia:/usr/local/lib/python3.10/dist-packages/tensorrt_libs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/lib/python3.10/dist-packages/tensorrt_libs\n",
        "!cat /usr/local/lib/python3.10/dist-packages/tensorrt_libs/__init__.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0r3pcm-DvNH",
        "outputId": "491a3995-2a94-466d-ee49-50ff08c98d9d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__.py\t\t\t\t   libnvinfer_plugin.so.10  __pycache__\n",
            "libnvinfer_builder_resource.so.10.5.0\t   libnvinfer.so.10\n",
            "libnvinfer_builder_resource_win.so.10.5.0  libnvonnxparser.so.10\n",
            "#\n",
            "# SPDX-FileCopyrightText: Copyright (c) 1993-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
            "# SPDX-License-Identifier: Apache-2.0\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of the License at\n",
            "#\n",
            "# http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "#\n",
            "\n",
            "import ctypes\n",
            "import glob\n",
            "import os\n",
            "import sys\n",
            "\n",
            "CURDIR = os.path.realpath(os.path.dirname(__file__))\n",
            "\n",
            "\n",
            "def try_load(library):\n",
            "    try:\n",
            "        ctypes.CDLL(library)\n",
            "    except OSError:\n",
            "        pass\n",
            "\n",
            "\n",
            "def try_load_libs_from_dir(path):\n",
            "    for lib in glob.iglob(os.path.join(path, \"*.so*\")):\n",
            "        try_load(lib)\n",
            "    for lib in glob.iglob(os.path.join(path, \"*.dll*\")):\n",
            "        try_load(lib)\n",
            "\n",
            "\n",
            "DEPENDENCY_PATHS = [\n",
            "    os.path.join(\"nvidia\", \"cuda_runtime\"),\n",
            "    os.path.join(\"nvidia\", \"cuda_nvrtc\"),\n",
            "]\n",
            "for dep_path in DEPENDENCY_PATHS:\n",
            "    try_load_libs_from_dir(\n",
            "        os.path.join(\n",
            "            CURDIR,\n",
            "            os.path.pardir,\n",
            "            dep_path,\n",
            "            \"bin\" if sys.platform.startswith(\"win\") else \"lib\",\n",
            "        )\n",
            "    )\n",
            "\n",
            "\n",
            "# Try loading all packaged libraries. This is a nop if there are no libraries packaged.\n",
            "try_load_libs_from_dir(CURDIR)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# !pip install tensorrt\n",
        "# Before training, it is recommended to first try the following code\n",
        "# to verify everything is okay and memory is sufficient:\n",
        "!python -m basic.cli --mode train --noload --debug\n",
        "note_err=\"\"\"\n",
        "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (10.5.0)\n",
        "Requirement already satisfied: tensorrt-cu12==10.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt) (10.5.0)\n",
        "2024-10-09 01:24:06.440695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
        "2024-10-09 01:24:06.459772: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
        "2024-10-09 01:24:06.469886: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
        "2024-10-09 01:24:07.705035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
        "Traceback (most recent call last):\n",
        "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
        "    return _run_code(code, main_globals, None,\n",
        "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
        "    exec(code, run_globals)\n",
        "  File \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig/basic/cli.py\", line 5, in <module>\n",
        "    from basic.main import main as m\n",
        "  File \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig/basic/main.py\", line 14, in <module>\n",
        "    from basic.model import get_multi_gpu_models\n",
        "  File \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig/basic/model.py\", line 12, in <module>\n",
        "    from my.tensorflow.rnn_cell import SwitchableDropoutWrapper, AttentionCell\n",
        "ModuleNotFoundError: No module named 'my.tensorflow.rnn_cell'\n",
        "CPU times: user 53.5 ms, sys: 11.4 ms, total: 64.8 ms\n",
        "Wall time: 6.84 s\n",
        "\n",
        "2024-08-18 23:19:24.895867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
        "https://github.com/tensorflow/tensorflow/issues/64809\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b22727-9408-4abc-8eb2-3888ec16012e",
        "id": "7OfAdoDTCpoc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-09 02:13:05.469103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-09 02:13:05.489416: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-09 02:13:05.496007: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-09 02:13:06.666284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig/basic/cli.py\", line 5, in <module>\n",
            "    from basic.main import main as m\n",
            "  File \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig/basic/main.py\", line 14, in <module>\n",
            "    from basic.model import get_multi_gpu_models\n",
            "  File \"/content/drive/MyDrive/GDcc4/ColabNotebooks/cc4_capstone/trivia_qa_bidaf_orig/basic/model.py\", line 12, in <module>\n",
            "    from my.tensorflow.rnn_cell import SwitchableDropoutWrapper, AttentionCell\n",
            "ModuleNotFoundError: No module named 'my.tensorflow.rnn_cell'\n",
            "CPU times: user 43 ms, sys: 1.58 ms, total: 44.6 ms\n",
            "Wall time: 4.93 s\n"
          ]
        }
      ]
    }
  ]
}